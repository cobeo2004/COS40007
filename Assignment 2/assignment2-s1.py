"""Assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q0ViTQcl-eAM4WGt6vKql3a3KKXvNri6

## Mount to Colab runtime
"""

from google.colab import drive
import sys
if('google.colab' in sys.modules):
  print("Google drive detected, mounting...")
  drive.mount('/content/gdrive')
else:
  print("No Google drive found, ignoring...")
print("Done checking")

"""## Installing dependencies"""

# Commented out IPython magic to ensure Python compatibility.
# print("Installing program...")
# if 'google.colab' in sys.modules:
#   !pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras torch opencv-python labelme statsmodels scipy missingno
# else:
#   %pip install -r studio2.req.txt

"""## Import dependencies"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from scipy import interpolate

import os
import warnings

"""## Define Config"""

warnings.filterwarnings('ignore')

pd.options.display.max_columns = None
pd.options.display.max_rows = None
pd.options.display.float_format = '{:.7f}'.format


"""## 1. Data Collection

### Define columns, file to read and what class should be used for that file
- Since my student ID ends with 2, thus I will be doing Right Upper Arm (x,y,z) and Left Upper Arm (x,y,z)
- Boning dataset will have a class of '0'
- Slicing dataset will have a class of '1'
- There will also be a 'Frame' column as well
"""

os.chdir("/content/gdrive/MyDrive") if 'google.colab' in sys.modules else None
BASE_PATH = os.getcwd() + "/Colab Notebooks/COS40007/Assignment 2/ampc2" if 'google.colab' in sys.modules else os.getcwd() + "/ampc2"
contents_to_read = {
    'boning': {
        'fName': BASE_PATH + '/Boning.csv',
        'class': 0
    },
    'slicing': {
        'fName': BASE_PATH + '/Slicing.csv',
        'class': 1
    }
}
columns_to_read = [f'Right Upper Arm {k}' for k in ['x', 'y', 'z']] + [f'Left Upper Arm {k}' for k in ['x', 'y', 'z']] + ['Frame']

"""### Read the dataset with chosen columns, append the 'class' feature to the file"""

boning_raw_df = pd.read_csv(contents_to_read['boning']['fName'], usecols=columns_to_read)
boning_df = boning_raw_df.copy()
boning_df['class'] = contents_to_read['boning']['class']
slicing_raw_df = pd.read_csv(contents_to_read['slicing']['fName'], usecols=columns_to_read)
slicing_df = slicing_raw_df.copy()
slicing_df['class'] = contents_to_read['slicing']['class']
print(f"Shape of boning: {boning_df.shape}")
print(f"Shape of slicing: {slicing_df.shape}")

"""### Concat two datasets to be one and save it as combined_data.csv"""

concatenated_df = pd.concat([boning_df, slicing_df], ignore_index=True)
concatenated_df.to_csv(BASE_PATH + "/combined_data.csv", index=False)
concatenated_df.info()