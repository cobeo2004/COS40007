{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOxlQy8aLvTKFLdd/QcpBKo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_7fDEz2WOpE","executionInfo":{"status":"ok","timestamp":1744461263728,"user_tz":-600,"elapsed":3848,"user":{"displayName":"Nguyễn Xuân Tuấn Minh","userId":"15433657071948479472"}},"outputId":"6e7274a9-eb87-457f-d3a1-d9e2d88b35b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import sys\n","from google.colab import drive\n","\n","if 'google.colab' in sys.modules:\n","  drive.mount('/content/drive')\n","  os.chdir('/content/drive/MyDrive/Colab Notebooks/COS40007/Assignment4')"]},{"cell_type":"code","source":["if 'google.colab' in sys.modules:\n","  %pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","  # !pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n","  %pip install torch torchaudio torchvision torchtext torchdata\n","  %pip install labelme2coco\n","else:\n","  !pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","  !pip install labelme2coco\n","  !pip install torch torchaudio torchvision torchtext torchdata"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SfJx_Jr7Ytra","executionInfo":{"status":"ok","timestamp":1744461370652,"user_tz":-600,"elapsed":106925,"user":{"displayName":"Nguyễn Xuân Tuấn Minh","userId":"15433657071948479472"}},"outputId":"e28d00fb-ed11-431c-d29e-52b79ade81b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/facebookresearch/detectron2.git\n","  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-7ah9mcox\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-7ah9mcox\n","  Resolved https://github.com/facebookresearch/detectron2.git to commit 9604f5995cc628619f0e4fd913453b4d7d61db3f\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.0.1)\n","Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n","Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n","Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.9)\n","Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n","Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (1.3.2)\n","Requirement already satisfied: black in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (25.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (1.0.0)\n","Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (0.12.1)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.7)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.71.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (5.29.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Collecting torchtext\n","  Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Collecting torchdata\n","  Using cached torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2025.1.31)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext, torchdata\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchdata-0.11.0 torchtext-0.18.0\n","Collecting labelme2coco\n","  Downloading labelme2coco-0.2.6-py3-none-any.whl.metadata (3.5 kB)\n","Collecting sahi>=0.8.19 (from labelme2coco)\n","  Downloading sahi-0.11.22-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from labelme2coco) (4.23.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->labelme2coco) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->labelme2coco) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->labelme2coco) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->labelme2coco) (0.24.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi>=0.8.19->labelme2coco) (8.1.8)\n","Collecting fire (from sahi>=0.8.19->labelme2coco)\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting opencv-python<=4.10.0.84 (from sahi>=0.8.19->labelme2coco)\n","  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: pillow>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from sahi>=0.8.19->labelme2coco) (11.1.0)\n","Collecting pybboxes==0.1.6 (from sahi>=0.8.19->labelme2coco)\n","  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from sahi>=0.8.19->labelme2coco) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from sahi>=0.8.19->labelme2coco) (2.32.3)\n","Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi>=0.8.19->labelme2coco) (2.1.0)\n","Collecting terminaltables (from sahi>=0.8.19->labelme2coco)\n","  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.11/dist-packages (from sahi>=0.8.19->labelme2coco) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pybboxes==0.1.6->sahi>=0.8.19->labelme2coco) (2.0.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6.0->labelme2coco) (4.13.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->sahi>=0.8.19->labelme2coco) (3.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->sahi>=0.8.19->labelme2coco) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->sahi>=0.8.19->labelme2coco) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->sahi>=0.8.19->labelme2coco) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->sahi>=0.8.19->labelme2coco) (2025.1.31)\n","Downloading labelme2coco-0.2.6-py3-none-any.whl (19 kB)\n","Downloading sahi-0.11.22-py3-none-any.whl (114 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n","Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=30568eea9417ae71cea5b601d1542aadd1b9ba357cef486bd46c605e7aa225cc\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","Successfully built fire\n","Installing collected packages: terminaltables, pybboxes, opencv-python, fire, sahi, labelme2coco\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.11.0.86\n","    Uninstalling opencv-python-4.11.0.86:\n","      Successfully uninstalled opencv-python-4.11.0.86\n","Successfully installed fire-0.7.0 labelme2coco-0.2.6 opencv-python-4.10.0.84 pybboxes-0.1.6 sahi-0.11.22 terminaltables-3.1.10\n"]}]},{"cell_type":"code","source":["import cv2\n","import torch\n","import json\n","from detectron2 import engine, config, utils, data, structures, engine, checkpoint, model_zoo\n","import labelme2coco\n","import random"],"metadata":{"id":"eHcAdyf0ZAkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BASE_PATH = os.getcwd()\n","DS_LOG_PATH = os.path.join(BASE_PATH, \"log-labelled\")\n","DS_CONVERTED_PATH = os.path.join(BASE_PATH, \"converted-labelled\")\n","ML_OUT_PATH = os.path.join(BASE_PATH, \"model-output\")\n","IMG_OUT_PATH = os.path.join(BASE_PATH, \"result-image\")\n","\n","print(BASE_PATH)\n","print(DS_LOG_PATH)\n","print(DS_CONVERTED_PATH)\n","print(ML_OUT_PATH)\n","print(IMG_OUT_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLMrb4JaZeGx","executionInfo":{"status":"ok","timestamp":1744461386280,"user_tz":-600,"elapsed":3,"user":{"displayName":"Nguyễn Xuân Tuấn Minh","userId":"15433657071948479472"}},"outputId":"5c756dee-bd22-4066-a091-d71f2155f0d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/COS40007/Assignment4\n","/content/drive/MyDrive/Colab Notebooks/COS40007/Assignment4/log-labelled\n","/content/drive/MyDrive/Colab Notebooks/COS40007/Assignment4/converted-labelled\n","/content/drive/MyDrive/Colab Notebooks/COS40007/Assignment4/model-output\n","/content/drive/MyDrive/Colab Notebooks/COS40007/Assignment4/result-image\n"]}]},{"cell_type":"code","source":["def ensure_folder_exists():\n","  \"\"\"\n","  Utility function to create neccessary directories if not exists\n","  :return: None\n","  \"\"\"\n","  if not os.path.exists(DS_CONVERTED_PATH):\n","    os.makedirs(DS_CONVERTED_PATH)\n","  if not os.path.exists(ML_OUT_PATH):\n","    os.makedirs(ML_OUT_PATH)\n","  if not os.path.exists(IMG_OUT_PATH):\n","    os.makedirs(IMG_OUT_PATH)"],"metadata":{"id":"8OQrQYxOaX8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def with_model_config():\n","  \"\"\"\n","  Utility function to define config for the Mask RCNN\n","  :return: detectron2.config.Config\n","  \"\"\"\n","  _config = config.get_cfg()\n","  # Merge from config file using COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x\n","  _config.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","  # Force to run with cuda, if not you can set it with CPU\n","  _config.MODEL.DEVICE = \"cuda\"\n","  # Model output directory\n","  _config.MODEL_OUTPUT_DIR = ML_OUT_PATH\n","  # Config model's weights using COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x\n","  _config.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","  # Number of classes for Region of Interests (RoI)\n","  _config.MODEL.ROI_HEADS.NUM_CLASSES = 1\n","  # Define batch size per image, recommend 128\n","  _config.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n","  # Max iteration between epochs\n","  _config.SOLVER.MAX_ITER = 100\n","  # Base LR\n","  _config.SOLVER.BASE_LR = 0.00025\n","  # Image per batch\n","  _config.SOLVER.IMS_PER_BATCH = 2\n","  # Number of workers, recommended 2\n","  _config.DATALOADER.NUM_WORKERS = 2\n","  # If there are no log_train or log_val, assign it as Train and Test datasets\n","  if not _config.DATASETS.TRAIN == (\"log_train\",) and not _config.DATASETS.TEST == (\"log_val\",):\n","    _config.DATASETS.TRAIN = (\"log_train\",)\n","    _config.DATASETS.TEST = (\"log_val\",)\n","\n","  return _config"],"metadata":{"id":"gl6fETcya7uH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def use_test_images():\n","  \"\"\"\n","  Utility function to randomly extract 10 images for testing\n","  :return: None\n","  \"\"\"\n","  _images = []\n","  for file in os.listdir(DS_LOG_PATH):\n","    if file.endswith('.png'):\n","      _images.append(file)\n","\n","  _test_images = random.sample(_images, 10)\n","  return _test_images\n","\n","def convert_from_labelme_to_coco():\n","  \"\"\"\n","  Function to convert from labelme to coco\n","  :return: None\n","  \"\"\"\n","  labelme2coco.convert(labelme_folder=DS_LOG_PATH, export_dir=DS_CONVERTED_PATH, train_split_rate=0.9, category_id_start=1)"],"metadata":{"id":"H0_cVV_Aehn2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_log(img_dir, json_file):\n","  \"\"\"\n","  Utility function to extract necessary data from coco dataset for registering datasets via detectron2.data.DatasetCatalog.register\n","  :img_dir: Directory contains images\n","  :json_file: Directory to put the val and train data in json format\n","  :return: Extracted Logs\n","  \"\"\"\n","  # Load coco data\n","  _json_dir = os.path.join(img_dir, json_file)\n","  _imported_coco_data = json.load(open(_json_dir))\n","  extracted_logs = []\n","\n","  # Looking for images tag in coco data\n","  for img in _imported_coco_data['images']:\n","    temp = {}\n","    # Set file name to the right path\n","    fName = os.path.join(img_dir, img['file_name'])\n","    temp[\"file_name\"] = fName\n","    # Set the image_id using id tag in json\n","    temp[\"image_id\"] = img['id']\n","    # Set the height using height tag in json\n","    temp[\"height\"] = img['height']\n","    # Set the width using width tag in json\n","    temp[\"width\"] = img['width']\n","\n","    # Extract important annotations metadata inside annotations tag if image_id is equal to id\n","    annots = [a for a in _imported_coco_data['annotations'] if a['image_id'] == img['id']]\n","    annotations = []\n","\n","    for ann in annots:\n","      # Convert and append to the annotations array\n","      inner_anno = {\n","          \"bbox\": ann['bbox'],\n","          \"bbox_mode\": structures.BoxMode.XYWH_ABS,\n","          \"segmentation\": ann['segmentation'],\n","          \"category_id\": ann['category_id'] - 1\n","      }\n","      annotations.append(inner_anno)\n","    # Then set it as annotations\n","    temp[\"annotations\"] = annotations\n","    # Append to the extracted logs array, end of pipeline\n","    extracted_logs.append(temp)\n","  # Return the extracted logs\n","  return extracted_logs"],"metadata":{"id":"sxqKopqpgxPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reg_datasets():\n","  \"\"\"\n","  Function to register extracted informations to detectron2\n","  :return: None\n","  \"\"\"\n","  keys = [\"train\", \"val\"]\n","  for k in keys:\n","    data.DatasetCatalog.register(\"log_\" + k, lambda k=k: extract_log(DS_CONVERTED_PATH, f\"{k}.json\"))\n","    data.MetadataCatalog.get(\"log_\" + k).set(thing_classes=[\"log\"])"],"metadata":{"id":"uULAGXscjmz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualiser(with_predictor, img_path, out_path):\n","  \"\"\"\n","  Function to write the predicted images to a specific output path\n","  :with_predictor: Trained ML Model\n","  :img_path: Image location\n","  :out_path: Path to write predicted image\n","  :return: Output of predictor\n","  \"\"\"\n","\n","  # Read and predict image\n","  imr = cv2.imread(img_path)\n","  out = with_predictor(imr)\n","\n","  # Get predicted boxes and scores\n","  instances = out[\"instances\"].to(\"cpu\")\n","  boxes = instances.pred_boxes.tensor.numpy()\n","  scores = instances.scores.numpy()\n","\n","  # Iterate and draw output box with the score\n","  for box, score in zip(boxes, scores):\n","    x1, y1, x2, y2 = box.astype(int)\n","    box_color = (69, 173, 130)\n","    text_color = (0, 0, 0)\n","    cv2.rectangle(imr, (x1, y1), (x2, y2), box_color, 2)\n","    cv2.putText(imr, f\"log: {score:.2f}\", (x1, y1-10), cv2.FONT_HERSHEY_PLAIN, 0.5, text_color, 2)\n","\n","  # Write the processed image to the output path\n","  cv2.imwrite(out_path, imr)\n","  return out"],"metadata":{"id":"NvTdf0uNkP_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def counter(outs):\n","  \"\"\"\n","  Function to count number of logs\n","  \"\"\"\n","  return len(outs[\"instances\"])"],"metadata":{"id":"BYPeTAL7laLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ensure_folder_exists()\n","cfg = with_model_config()\n","IS_TRAIN = True\n","\n","if IS_TRAIN:\n","  convert_from_labelme_to_coco()\n","  reg_datasets()\n","\n","  trainer = engine.DefaultTrainer(cfg)\n","  trainer.resume_or_load(resume=False)\n","\n","  trainer.train()\n","\n","  checker = checkpoint.DetectionCheckpointer(trainer.model, save_dir=cfg.MODEL_OUTPUT_DIR)\n","  checker.save(\"final_model\")\n","\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.MODEL_OUTPUT_DIR, \"final_model.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.66\n","\n","pred = engine.DefaultPredictor(cfg)\n","test_imgs = use_test_images()\n","\n","for img in test_imgs:\n","  img_path = os.path.join(DS_LOG_PATH, img)\n","  out_path = os.path.join(IMG_OUT_PATH, f\"result_{img}\")\n","\n","  outputs = visualiser(pred, img_path, out_path)\n","\n","  print(f\"Detected logs in {img} are: {counter(outputs)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLNsCW3Xlh5m","executionInfo":{"status":"ok","timestamp":1744461567438,"user_tz":-600,"elapsed":181019,"user":{"displayName":"Nguyễn Xuân Tuấn Minh","userId":"15433657071948479472"}},"outputId":"d3038968-35c7-4ffe-f4c9-fb2408c5c972"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 600 listed files in folder log-labelled.\n"]},{"output_type":"stream","name":"stderr","text":["Converting labelme annotations to COCO format: 100%|██████████| 600/600 [01:51<00:00,  5.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[04/12 12:38:22 d2.engine.defaults]: Model:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","[04/12 12:38:22 d2.data.build]: Removed 0 images with no usable annotations. 540 images left.\n","[04/12 12:38:22 d2.data.build]: Distribution of instances among all 1 categories:\n","|  category  | #instances   |\n","|:----------:|:-------------|\n","|    log     | 5284         |\n","|            |              |\n","[04/12 12:38:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","[04/12 12:38:22 d2.data.build]: Using training sampler TrainingSampler\n","[04/12 12:38:22 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[04/12 12:38:22 d2.data.common]: Serializing 540 elements to byte tensors and concatenating them all ...\n","[04/12 12:38:22 d2.data.common]: Serialized dataset takes 0.96 MiB\n","[04/12 12:38:22 d2.data.build]: Making batched data loader with batch_size=2\n","WARNING [04/12 12:38:22 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","[04/12 12:38:22 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"]},{"output_type":"stream","name":"stderr","text":["model_final_f10217.pkl: 178MB [00:01, 141MB/s]                           \n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n","roi_heads.box_predictor.bbox_pred.{bias, weight}\n","roi_heads.box_predictor.cls_score.{bias, weight}\n","roi_heads.mask_head.predictor.{bias, weight}\n"]},{"output_type":"stream","name":"stdout","text":["[04/12 12:38:24 d2.engine.train_loop]: Starting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["[04/12 12:38:36 d2.utils.events]:  eta: 0:00:33  iter: 19  total_loss: 2.215  loss_cls: 0.6639  loss_box_reg: 0.7971  loss_mask: 0.6773  loss_rpn_cls: 0.03613  loss_rpn_loc: 0.02763    time: 0.4428  last_time: 0.4084  data_time: 0.0255  last_data_time: 0.0058   lr: 4.7703e-05  max_mem: 2047M\n","[04/12 12:38:54 d2.utils.events]:  eta: 0:00:25  iter: 39  total_loss: 1.841  loss_cls: 0.4702  loss_box_reg: 0.8408  loss_mask: 0.512  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.02842    time: 0.4528  last_time: 0.4147  data_time: 0.0114  last_data_time: 0.0088   lr: 9.7653e-05  max_mem: 2047M\n","[04/12 12:39:02 d2.utils.events]:  eta: 0:00:17  iter: 59  total_loss: 1.534  loss_cls: 0.3224  loss_box_reg: 0.8303  loss_mask: 0.3352  loss_rpn_cls: 0.009215  loss_rpn_loc: 0.02558    time: 0.4495  last_time: 0.4885  data_time: 0.0099  last_data_time: 0.0085   lr: 0.0001476  max_mem: 2047M\n","[04/12 12:39:12 d2.utils.events]:  eta: 0:00:08  iter: 79  total_loss: 1.224  loss_cls: 0.2249  loss_box_reg: 0.719  loss_mask: 0.2446  loss_rpn_cls: 0.004778  loss_rpn_loc: 0.02266    time: 0.4533  last_time: 0.4278  data_time: 0.0123  last_data_time: 0.0085   lr: 0.00019755  max_mem: 2047M\n","[04/12 12:39:22 d2.utils.events]:  eta: 0:00:00  iter: 99  total_loss: 0.8315  loss_cls: 0.1439  loss_box_reg: 0.5041  loss_mask: 0.1693  loss_rpn_cls: 0.003225  loss_rpn_loc: 0.0217    time: 0.4529  last_time: 0.4463  data_time: 0.0065  last_data_time: 0.0071   lr: 0.0002475  max_mem: 2047M\n","[04/12 12:39:22 d2.engine.hooks]: Overall training speed: 98 iterations in 0:00:44 (0.4529 s / it)\n","[04/12 12:39:22 d2.engine.hooks]: Total training time: 0:00:53 (0:00:09 on hooks)\n","[04/12 12:39:22 d2.data.build]: Distribution of instances among all 1 categories:\n","|  category  | #instances   |\n","|:----------:|:-------------|\n","|    log     | 591          |\n","|            |              |\n","[04/12 12:39:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[04/12 12:39:22 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[04/12 12:39:22 d2.data.common]: Serializing 60 elements to byte tensors and concatenating them all ...\n","[04/12 12:39:22 d2.data.common]: Serialized dataset takes 0.11 MiB\n","WARNING [04/12 12:39:22 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","[04/12 12:39:24 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/Colab Notebooks/COS40007/Assignment4/model-output/final_model.pth ...\n","Detected logs in 00353-ZED-Left-1622131977.png are: 11\n","Detected logs in 00450-ZED-Left-1622131421.png are: 8\n","Detected logs in 00371-ZED-Left-1622132909.png are: 11\n","Detected logs in 00601-ZED-Left-1622129539.png are: 10\n","Detected logs in 00578-ZED-Right-1622133155.png are: 9\n","Detected logs in 00493-ZED-Left-1622133722.png are: 10\n","Detected logs in 00482-ZED-Left-1622133126.png are: 10\n","Detected logs in 00566-ZED-Left-1622132559.png are: 10\n","Detected logs in 00484-ZED-Left-1622133240.png are: 8\n","Detected logs in 00403-ZED-Left-1622128970.png are: 9\n"]}]}]}